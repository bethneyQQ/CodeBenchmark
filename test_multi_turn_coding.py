#!/usr/bin/env python3
"""
æµ‹è¯•multi-turn-codingä»»åŠ¡çš„å®Œæ•´æµç¨‹
é€šè¿‡Evaluation Engineè°ƒç”¨çœŸå®çš„multi-turn-codingä»»åŠ¡
"""

import sys
import logging
import os
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_multi_turn_coding_task():
    """æµ‹è¯•multi-turn-codingä»»åŠ¡"""
    print("ğŸš€ æµ‹è¯• Multi-Turn Coding ä»»åŠ¡")
    print("=" * 70)
    
    try:
        # 1. å¯¼å…¥æ ¸å¿ƒç»„ä»¶
        print("\n1ï¸âƒ£ å¯¼å…¥Evaluation Engineæ ¸å¿ƒç»„ä»¶...")
        
        from evaluation_engine.core.unified_framework import (
            UnifiedEvaluationFramework, 
            EvaluationRequest, 
            ExecutionStatus
        )
        
        print("âœ… æˆåŠŸå¯¼å…¥UnifiedEvaluationFramework")
        
        # 2. åˆå§‹åŒ–æ¡†æ¶
        print("\n2ï¸âƒ£ åˆå§‹åŒ–è¯„ä¼°æ¡†æ¶...")
        unified_framework = UnifiedEvaluationFramework()
        print("âœ… è¯„ä¼°æ¡†æ¶åˆå§‹åŒ–å®Œæˆ")
        
        # 3. å‘ç°multi-turn-codingä»»åŠ¡
        print("\n3ï¸âƒ£ å‘ç°multi-turn-codingä»»åŠ¡...")
        all_tasks = unified_framework.list_available_tasks()
        
        # æŸ¥æ‰¾multi-turnç›¸å…³ä»»åŠ¡
        multi_turn_tasks = [t for t in all_tasks if "multi_turn" in t.lower()]
        print(f"âœ… å‘ç° {len(multi_turn_tasks)} ä¸ªmulti-turnä»»åŠ¡:")
        
        for task in multi_turn_tasks[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
            print(f"   - {task}")
        
        if len(multi_turn_tasks) > 10:
            print(f"   ... è¿˜æœ‰ {len(multi_turn_tasks) - 10} ä¸ªä»»åŠ¡")
        
        # é€‰æ‹©è¦æµ‹è¯•çš„ä»»åŠ¡
        if not multi_turn_tasks:
            print("âŒ æ²¡æœ‰å‘ç°multi-turnä»»åŠ¡")
            return False
        
        # ä¼˜å…ˆé€‰æ‹©multi_turn_codingç›¸å…³ä»»åŠ¡
        target_task = None
        for task in multi_turn_tasks:
            if "coding" in task.lower():
                target_task = task
                break
        
        if not target_task:
            target_task = multi_turn_tasks[0]
        
        print(f"ğŸ¯ é€‰æ‹©æµ‹è¯•ä»»åŠ¡: {target_task}")
        
        # 4. æ£€æŸ¥ä»»åŠ¡ä¿¡æ¯
        print("\n4ï¸âƒ£ è·å–ä»»åŠ¡è¯¦ç»†ä¿¡æ¯...")
        task_info = unified_framework.get_task_info(target_task)
        
        if task_info:
            print(f"âœ… ä»»åŠ¡ä¿¡æ¯:")
            print(f"   - ä»»åŠ¡å: {task_info['task_name']}")
            print(f"   - å¯ç”¨æ€§: {task_info['available']}")
            print(f"   - å¤šè½®å¯¹è¯: {task_info['is_multi_turn']}")
        else:
            print("âš ï¸ æ— æ³•è·å–è¯¦ç»†ä»»åŠ¡ä¿¡æ¯ï¼Œç»§ç»­æ‰§è¡Œ")
        
        # 5. è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        print("\n5ï¸âƒ£ é…ç½®ç¯å¢ƒå˜é‡...")
        
        # æ£€æŸ¥APIå¯†é’¥
        api_keys = {
            'ANTHROPIC_API_KEY': os.getenv('ANTHROPIC_API_KEY'),
            'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY'),
            'DEEPSEEK_API_KEY': os.getenv('DEEPSEEK_API_KEY'),
            'DASHSCOPE_API_KEY': os.getenv('DASHSCOPE_API_KEY')
        }
        
        available_keys = [k for k, v in api_keys.items() if v]
        if available_keys:
            print(f"âœ… å¯ç”¨çš„APIå¯†é’¥: {available_keys}")
        else:
            print("âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ°APIå¯†é’¥ï¼Œå°†ä½¿ç”¨dummyæ¨¡å‹")
        
        # è®¾ç½®multi-turn codingç‰¹å®šçš„ç¯å¢ƒå˜é‡
        os.environ.setdefault('ENABLE_PRD_CONTEXT', 'true')
        os.environ.setdefault('ENABLE_DESIGN_CONTEXT', 'true')
        os.environ.setdefault('ENABLE_CODE_CONTEXT', 'true')
        os.environ.setdefault('ENABLE_QUALITY_CONTEXT', 'true')
        
        print("âœ… Multi-turn codingç¯å¢ƒå˜é‡å·²è®¾ç½®")
        
        # 6. åˆ›å»ºè¯„ä¼°è¯·æ±‚
        print("\n6ï¸âƒ£ åˆ›å»ºè¯„ä¼°è¯·æ±‚...")
        
        # é€‰æ‹©æ¨¡å‹
        if os.getenv('ANTHROPIC_API_KEY'):
            model_id = "claude-local"
            model_args = "model=claude-3-haiku-20240307"
            print("ğŸ¤– ä½¿ç”¨Claudeæ¨¡å‹")
        elif os.getenv('OPENAI_API_KEY'):
            model_id = "openai-completions"
            model_args = "model=gpt-3.5-turbo"
            print("ğŸ¤– ä½¿ç”¨OpenAIæ¨¡å‹")
        else:
            model_id = "dummy"
            model_args = ""
            print("ğŸ¤– ä½¿ç”¨Dummyæ¨¡å‹ï¼ˆæµ‹è¯•ç”¨ï¼‰")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("results/multi_turn_coding_test")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        evaluation_request = EvaluationRequest(
            model=model_id,
            tasks=[target_task],
            limit=1,  # åªæµ‹è¯•1ä¸ªé—®é¢˜
            num_fewshot=0,
            batch_size=1,
            use_cache=True,
            write_out=True,
            output_base_path=str(output_dir),
            log_samples=True,
            verbosity="INFO",
            gen_kwargs={
                "temperature": 0.0,  # multi-turn codingæ¨èä½¿ç”¨0æ¸©åº¦
                "max_gen_toks": 800,
                "do_sample": False
            }
        )
        
        print(f"âœ… è¯„ä¼°è¯·æ±‚åˆ›å»ºå®Œæˆ:")
        print(f"   - æ¨¡å‹: {model_id}")
        print(f"   - ä»»åŠ¡: {target_task}")
        print(f"   - é™åˆ¶: {evaluation_request.limit}")
        print(f"   - è¾“å‡ºç›®å½•: {output_dir}")
        
        # 7. éªŒè¯è¯·æ±‚
        print("\n7ï¸âƒ£ éªŒè¯è¯„ä¼°è¯·æ±‚...")
        validation_issues = unified_framework.validate_evaluation_request(evaluation_request)
        
        if validation_issues:
            print(f"âš ï¸ éªŒè¯å‘ç°é—®é¢˜:")
            for issue in validation_issues:
                print(f"   - {issue}")
            print("ç»§ç»­æ‰§è¡Œ...")
        else:
            print("âœ… è¯„ä¼°è¯·æ±‚éªŒè¯é€šè¿‡")
        
        # 8. æ‰§è¡Œè¯„ä¼°
        print("\n8ï¸âƒ£ æ‰§è¡ŒMulti-Turn Codingè¯„ä¼°...")
        print("   ğŸ“Š å¼€å§‹æ‰§è¡Œè¯„ä¼°ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
        print(f"   - æ¨¡å‹: {evaluation_request.model}")
        print(f"   - ä»»åŠ¡: {evaluation_request.tasks}")
        print(f"   - é…ç½®: limit={evaluation_request.limit}, temperature={evaluation_request.gen_kwargs.get('temperature', 'N/A')}")
        
        # æ‰§è¡Œè¯„ä¼°
        result = unified_framework.evaluate(evaluation_request)
        
        print(f"âœ… è¯„ä¼°æ‰§è¡Œå®Œæˆ!")
        print(f"   - è¯„ä¼°ID: {result.evaluation_id}")
        print(f"   - çŠ¶æ€: {result.status.value}")
        print(f"   - å¼€å§‹æ—¶é—´: {result.start_time}")
        print(f"   - ç»“æŸæ—¶é—´: {result.end_time}")
        
        if result.error:
            print(f"   - é”™è¯¯: {result.error}")
        
        # 9. åˆ†æç»“æœ
        print("\n9ï¸âƒ£ åˆ†æMulti-Turn Codingç»“æœ...")
        
        if result.status == ExecutionStatus.COMPLETED:
            print("âœ… Multi-Turn Codingè¯„ä¼°æˆåŠŸå®Œæˆ!")
            
            # æ˜¾ç¤ºåŸå§‹ç»“æœ
            if result.results:
                print("   ğŸ“Š åŸå§‹ç»“æœ:")
                for task_name, task_result in result.results.items():
                    print(f"     - {task_name}:")
                    if isinstance(task_result, dict):
                        for metric, value in task_result.items():
                            if isinstance(value, (int, float)):
                                print(f"       * {metric}: {value:.3f}")
                            else:
                                print(f"       * {metric}: {value}")
            
            # æ˜¾ç¤ºæŒ‡æ ‡æ‘˜è¦
            if result.metrics_summary:
                print("   ğŸ“ˆ æŒ‡æ ‡æ‘˜è¦:")
                for metric, value in result.metrics_summary.items():
                    print(f"     - {metric}: {value:.3f}")
            
            # æ˜¾ç¤ºåˆ†ææŠ¥å‘Š
            if result.analysis:
                print("   ğŸ“‹ åˆ†ææŠ¥å‘Š:")
                analysis = result.analysis
                
                if 'summary' in analysis:
                    print(f"     - æ‘˜è¦: {analysis['summary']}")
                
                if 'performance_insights' in analysis:
                    insights = analysis['performance_insights']
                    print(f"     - æ•´ä½“è¡¨ç°: {insights.get('overall_performance', 'unknown')}")
                
                if 'recommendations' in analysis and analysis['recommendations']:
                    print("     - å»ºè®®:")
                    for rec in analysis['recommendations'][:3]:
                        print(f"       * {rec}")
            
            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            exec_time = unified_framework._calculate_execution_time(result)
            print(f"   â±ï¸ æ‰§è¡Œæ—¶é—´: {exec_time:.2f}ç§’")
            
            # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
            print("\n   ğŸ“ æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶:")
            if output_dir.exists():
                for item in output_dir.rglob("*"):
                    if item.is_file():
                        print(f"     - {item.relative_to(output_dir)}")
            
        else:
            print(f"âŒ Multi-Turn Codingè¯„ä¼°æœªæˆåŠŸå®Œæˆ: {result.status.value}")
            if result.error:
                print(f"   é”™è¯¯è¯¦æƒ…: {result.error}")
        
        # 10. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        print("\nğŸ”Ÿ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
        
        report = {
            "test_timestamp": datetime.now().isoformat(),
            "multi_turn_coding_test": "COMPLETED",
            "task_tested": target_task,
            "model_used": model_id,
            "evaluation_result": {
                "evaluation_id": result.evaluation_id,
                "status": result.status.value,
                "execution_time": exec_time if result.status == ExecutionStatus.COMPLETED else 0,
                "error": result.error
            },
            "metrics_summary": result.metrics_summary or {},
            "analysis_available": bool(result.analysis),
            "files_generated": len(list(output_dir.rglob("*"))) if output_dir.exists() else 0
        }
        
        # ä¿å­˜æŠ¥å‘Š
        import json
        report_file = "multi_turn_coding_test_report.json"
        with open(report_file, "w") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        print("\nğŸ‰ Multi-Turn Codingä»»åŠ¡æµ‹è¯•å®Œæˆ!")
        print("=" * 70)
        
        success = result.status == ExecutionStatus.COMPLETED
        
        if success:
            print("âœ… æµ‹è¯•ç»“æœ: æˆåŠŸ")
            print("ğŸ’¡ éªŒè¯å†…å®¹:")
            print("  - Multi-Turn Codingä»»åŠ¡å‘ç°å’ŒåŠ è½½")
            print("  - Evaluation Engineé›†æˆ")
            print("  - çœŸå®ä»»åŠ¡æ‰§è¡Œ")
            print("  - ç»“æœåˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ")
            
            print("\nğŸ“š ç›¸å…³æ–‡ä»¶:")
            print(f"  - æµ‹è¯•æŠ¥å‘Š: {report_file}")
            print(f"  - è¾“å‡ºç›®å½•: {output_dir}")
            print("  - Multi-Turn Codingä»»åŠ¡: lm_eval/tasks/multi_turn_coding/")
            
        else:
            print("âš ï¸ æµ‹è¯•ç»“æœ: éƒ¨åˆ†æˆåŠŸ")
            print("ğŸ’¡ å·²éªŒè¯:")
            print("  - Multi-Turn Codingä»»åŠ¡å‘ç°")
            print("  - Evaluation Engineé›†æˆ")
            print("  - è¯„ä¼°æµç¨‹æ‰§è¡Œ")
            
        return success
        
    except Exception as e:
        print(f"\nğŸ’¥ Multi-Turn Codingä»»åŠ¡æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª Multi-Turn Coding ä»»åŠ¡æµ‹è¯•")
    print("æµ‹è¯•é€šè¿‡Evaluation Engineè°ƒç”¨çœŸå®çš„multi-turn-codingä»»åŠ¡")
    print()
    
    try:
        success = test_multi_turn_coding_task()
        
        if success:
            print("\nğŸ’¡ æµ‹è¯•æ€»ç»“:")
            print("  âœ… æˆåŠŸè°ƒç”¨äº†multi-turn-codingä»»åŠ¡")
            print("  âœ… éªŒè¯äº†Evaluation Engineä¸multi-turnä»»åŠ¡çš„é›†æˆ")
            print("  âœ… å±•ç¤ºäº†å®Œæ•´çš„å¤šè½®å¯¹è¯è¯„ä¼°æµç¨‹")
            print("  âœ… ç”Ÿæˆäº†çœŸå®çš„è¯„ä¼°ç»“æœå’Œåˆ†æ")
            
            print("\nğŸš€ åç»­å»ºè®®:")
            print("  1. é…ç½®çœŸå®çš„APIå¯†é’¥ä»¥è·å¾—æ›´å¥½çš„ç»“æœ")
            print("  2. å°è¯•ä¸åŒçš„éš¾åº¦çº§åˆ«å’Œä»»åŠ¡ç±»å‹")
            print("  3. åˆ†æç”Ÿæˆçš„æ–‡ä»¶å’Œä»£ç è´¨é‡")
            print("  4. ä½¿ç”¨multi-turn-codingçš„åˆ†æå·¥å…·")
            
            return 0
        else:
            print("\nğŸ’¥ æµ‹è¯•æœªå®Œå…¨æˆåŠŸï¼Œä½†å·²éªŒè¯åŸºæœ¬é›†æˆ")
            return 1
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 0
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•å¼‚å¸¸: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())