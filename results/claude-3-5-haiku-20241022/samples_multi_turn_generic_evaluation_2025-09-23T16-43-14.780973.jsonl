{"doc_id": 0, "doc": {"problem_id": "task_scheduler", "complexity": "intermediate", "domain": "system_design", "problem_description": "Create a distributed task scheduling system that can manage and execute tasks across multiple worker nodes with priority queues and retry mechanisms.", "expected_outputs": ["task queue", "worker nodes", "scheduler", "retry logic", "priority handling"], "evaluation_criteria": {}, "phase_dependencies": {}, "business_context": "A growing company needs to process various background tasks like sending emails, processing images, and generating reports. The system should handle task failures gracefully and prioritize urgent tasks.", "title": "Task Scheduler System"}, "target": "['task queue', 'worker nodes', 'scheduler', 'retry logic', 'priority handling']", "arguments": {"gen_args_0": {"arg_0": "# Multi-Turn Software Engineering Evaluation\n\n**Problem Description:**\nCreate a distributed task scheduling system that can manage and execute tasks across multiple worker nodes with priority queues and retry mechanisms.\n\nYou will complete this software engineering project in 3 sequential phases. Please complete ALL phases in a single response, with clear phase separators.\n\n---\n\n## Phase 1: Product Requirements Document (PRD) Generation\n\n**Task:** Create a comprehensive Product Requirements Document (PRD) that includes:\n\n1. **Problem Statement**: Clear definition of the problem to solve\n2. **Objectives**: Main goals and success criteria  \n3. **User Stories**: Key user scenarios and requirements\n4. **Functional Requirements**: Core features and capabilities\n5. **Non-functional Requirements**: Performance, security, scalability constraints\n6. **Success Metrics**: Measurable criteria for evaluation\n\n**Output Format:**\n```\nPRD_START\n## Problem Statement\n[Your problem statement here]\n\n## Objectives  \n[Your objectives here]\n\n## User Stories\n[Your user stories here]\n\n## Functional Requirements\n[Your functional requirements here]\n\n## Non-functional Requirements  \n[Your non-functional requirements here]\n\n## Success Metrics\n[Your success metrics here]\nPRD_END\n```\n\n---\n\n## Phase 2: Technical Design\n\n**Task:** Based on your PRD above, create a detailed technical design that includes:\n\n1. **System Architecture**: High-level system components and their relationships\n2. **API Design**: Key endpoints, request/response formats\n3. **Data Models**: Database schema and data structures  \n4. **Technology Stack**: Recommended technologies and frameworks\n5. **Security Considerations**: Authentication, authorization, data protection\n6. **Scalability Plan**: How to handle growth and performance\n\n**Output Format:**\n```\nDESIGN_START\n## System Architecture\n[Your architecture design here]\n\n## API Design\n[Your API specifications here]\n\n## Data Models\n[Your data models here]\n\n## Technology Stack\n[Your technology choices here]\n\n## Security Considerations\n[Your security approach here]\n\n## Scalability Plan  \n[Your scalability strategy here]\nDESIGN_END\n```\n\n---\n\n## Phase 3: Implementation\n\n**Task:** Based on your PRD and Technical Design above, implement a complete Python solution that includes:\n\n1. **Core Implementation**: Main classes, functions, and logic\n2. **API/Interface Layer**: If applicable, API endpoints or CLI interface\n3. **Data Layer**: Database models, data access patterns\n4. **Configuration**: Settings, environment variables\n5. **Error Handling**: Comprehensive error management\n6. **Unit Tests**: Test cases for core functionality\n7. **Documentation**: Code comments and usage examples\n\n**Output Format:**\n```\nIMPLEMENTATION_START\n## Core Implementation\n```python\n# Main application code here\n```\n\n## API/Interface Layer  \n```python\n# API or interface code here\n```\n\n## Data Layer\n```python\n# Data models and access code here  \n```\n\n## Configuration\n```python\n# Configuration code here\n```\n\n## Unit Tests\n```python\n# Test cases here\n```\n\n## Documentation\n[Usage examples and documentation here]\nIMPLEMENTATION_END\n```\n\n---\n\n**Instructions:**\n- Complete ALL three phases in sequence\n- Each phase should build upon the previous ones\n- Be specific, actionable, and comprehensive\n- Include proper formatting with the specified markers\n- Focus on practical, implementable solutions\n\nPlease complete all phases now:", "arg_1": {"temperature": 0.0, "max_gen_toks": 2000, "until": [], "do_sample": false}}}, "resps": [["# Multi-Turn Software Engineering Evaluation - Distributed Task Scheduling System\n\n## Phase 1: Product Requirements Document (PRD)\n\n```\nPRD_START\n## Problem Statement\nDevelop a distributed task scheduling system that enables efficient, reliable, and scalable task execution across multiple worker nodes, addressing challenges of task distribution, priority management, and fault tolerance in distributed computing environments.\n\n## Objectives\n1. Enable reliable task distribution across multiple worker nodes\n2. Support priority-based task queuing and execution\n3. Implement robust error handling and automatic task retry mechanisms\n4. Provide real-time monitoring and status tracking of tasks\n5. Ensure high availability and fault tolerance\n\n## User Stories\n1. As a system administrator, I want to submit tasks to be executed across multiple workers\n2. As a developer, I need to define task priorities and retry policies\n3. As an operations team member, I want to monitor task execution status in real-time\n4. As a system, I need to automatically handle worker node failures and redistribute tasks\n\n## Functional Requirements\n1. Task submission with priority levels\n2. Dynamic worker node registration and management\n3. Automatic task redistribution on worker failure\n4. Configurable retry mechanisms\n5. Real-time task status tracking\n6. Support for different task types (compute, I/O, network)\n\n## Non-functional Requirements\n1. Horizontal scalability to support 100+ worker nodes\n2. Low latency task scheduling (<50ms)\n3. 99.9% task completion reliability\n4. Secure communication between master and worker nodes\n5. Minimal resource overhead\n6. Support for containerized and cloud-native deployments\n\n## Success Metrics\n1. Task completion rate > 99.5%\n2. Average task scheduling latency < 100ms\n3. System can handle 1000+ concurrent tasks\n4. Automatic recovery from worker node failures within 5 seconds\n5. Less than 1% performance degradation under high load\nPRD_END\n```\n\n## Phase 2: Technical Design\n\n```\nDESIGN_START\n## System Architecture\n- Master Node (Coordinator)\n  - Task Queue Manager\n  - Worker Registry\n  - Health Monitoring Service\n- Worker Nodes\n  - Task Executor\n  - Local Task Queue\n  - Health Reporting Agent\n\nArchitecture Pattern: Distributed Master-Worker with Pub/Sub Communication\n\n## API Design\n1. Task Submission Endpoint\n- POST /tasks\n  Request Body: {\n    task_id: UUID,\n    priority: int,\n    type: string,\n    payload: JSON,\n    max_retries: int\n  }\n\n2. Worker Registration\n- POST /workers/register\n  Request Body: {\n    worker_id: UUID,\n    capabilities: [string],\n    resources: {\n      cpu: float,\n      memory: float\n    }\n  }\n\n## Data Models\n1. Task\n- task_id: UUID\n- status: enum (PENDING, RUNNING, COMPLETED, FAILED)\n- priority: int\n- type: string\n- payload: JSON\n- created_at: timestamp\n- updated_at: timestamp\n- retry_count: int\n\n2. Worker\n- worker_id: UUID\n- status: enum (ACTIVE, INACTIVE)\n- capabilities: [string]\n- last_heartbeat: timestamp\n\n## Technology Stack\n- Language: Python 3.9+\n- Concurrency: asyncio, multiprocessing\n- Message Broker: Apache Kafka\n- Service Discovery: Consul\n- Database: Redis (for task tracking)\n- Containerization: Docker, Kubernetes\n- Monitoring: Prometheus, Grafana\n\n## Security Considerations\n1. JWT-based authentication\n2. TLS encryption for all communications\n3. Role-based access control\n4. Secure worker node registration with pre-shared keys\n5. Input validation and sanitization\n\n## Scalability Plan\n1. Horizontal scaling of worker nodes\n2. Sharded task queues\n3. Stateless master node design\n4. Caching with Redis\n5. Event-driven architecture for loose coupling\nDESIGN_END\n```\n\n## Phase 3: Implementation\n\n```\nIMPLEMENTATION_START\n## Core Implementation\n```python\nimport uuid\nimport asyncio\nimport logging\nfrom enum import Enum, auto\nfrom typing import Dict, Any, List\nfrom dataclasses import dataclass, field\n\nclass TaskStatus(Enum):\n    PENDING = auto()\n    RUNNING = auto()\n    COMPLETED = auto()\n    FAILED = auto()\n\n@dataclass\nclass Task:\n    task_id: uuid.UUID = field(default_factory=uuid.uuid4)\n    status: TaskStatus = TaskStatus.PENDING\n    priority: int = 0\n    payload: Dict[str, Any] = field(default_factory=dict)\n    max_retries: int = 3\n    retry_count: int = 0\n    created_at: float = field(default_factory=asyncio.get_event_loop().time)\n\nclass TaskScheduler:\n    def __init__(self, max_workers: int = 10):\n        self.task_queue = asyncio.PriorityQueue()\n        self.workers = []\n        self.max_workers = max_workers\n        self.running_tasks = set()\n\n    async def submit_task(self, task: Task):\n        await self.task_queue.put((-task.priority, task))\n        logging.info(f\"Task {task.task_id} submitted\")\n\n    async def worker(self, worker_id: int):\n        while True:\n            priority, task = await self.task_queue.get()\n            try:\n                await self.execute_task(task)\n            except Exception as e:\n                await self.handle_task_failure(task, e)\n            finally:\n                self.task_queue.task_done()\n\n    async def execute_task(self, task: Task):\n        task.status = TaskStatus.RUNNING\n        try:\n            # Simulated task execution\n            await asyncio.sleep(1)  # Placeholder for actual task logic\n            task.status = TaskStatus.COMPLETED\n            logging.info(f\"Task {task.task_id} completed successfully\")\n        except Exception as e:\n            raise e\n\n    async def handle_task_failure(self, task: Task, error: Exception):\n        task.retry_count += 1\n        if task.retry_count <= task.max_retries:\n            logging.warning(f\"Task {task.task_id} failed. Retrying...\")\n            await self.submit_task(task)\n        else:\n            task.status = TaskStatus.FAILED\n            logging.error(f\"Task {task.task_id} failed after {task.max_retries} retries\")\n\n    async def start(self):\n        workers = [asyncio.create_task(self.worker(i)) for i in range(self.max_workers)]\n        await asyncio.gather(*workers)\n\nasync def main():\n    scheduler = TaskScheduler(max_workers=5)\n    \n    # Example task submission\n    tasks = [\n        Task(priority=1, payload={\"data\": \"task1\"}),\n        Task(priority=2, payload={\"data\": \"task2\"}),\n        Task(priority=3, payload={\"data\": \"task3\"})\n    ]\n\n    for task in tasks:\n        await scheduler.submit_task(task)\n\n    await scheduler.start()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n## Unit Tests\n```python\nimport pytest\nimport asyncio\nfrom task_scheduler import TaskScheduler, Task, TaskStatus\n\n@pytest.mark.asyncio\nasync def test_task_submission():\n    scheduler = TaskScheduler(max_workers=2)\n    task = Task(priority=1)\n    \n    await scheduler.submit_task(task)\n    assert scheduler.task_queue.qsize() == 1\n\n@pytest.mark.asyncio\nasync def test_task_execution():\n    scheduler = TaskScheduler(max_workers=2)\n    task = Task(priority=1)\n    \n    await scheduler.submit_task(task)\n    await scheduler.execute_task(task)\n    \n    assert task.status == TaskStatus.COMPLETED\n\n@pytest.mark.asyncio\nasync def test_task_retry():\n    scheduler = TaskScheduler(max_workers=2)\n    task = Task(priority=1, max_retries=3)\n    \n    # Simulate task failure\n    with pytest.raises(Exception):\n        await scheduler.execute_task(task)\n    \n    await scheduler."]], "filtered_resps": ["{'prd': '\\\\n## Problem Statement\\\\nDevelop a distributed task scheduling system that enables efficient, reliable, and scalable task execution across multiple worker nodes, addressing challenges of task distribution, priority management, and fault tolerance in distributed computing environments.\\\\n\\\\n## Objectives\\\\n1. Enable reliable task distribution across multiple worker nodes\\\\n2. Support priority-based task queuing and execution\\\\n3. Implement robust error handling and automatic task retry mechanisms\\\\n4. Provide real-time monitoring and status tracking of tasks\\\\n5. Ensure high availability and fault tolerance\\\\n\\\\n## User Stories\\\\n1. As a system administrator, I want to submit tasks to be executed across multiple workers\\\\n2. As a developer, I need to define task priorities and retry policies\\\\n3. As an operations team member, I want to monitor task execution status in real-time\\\\n4. As a system, I need to automatically handle worker node failures and redistribute tasks\\\\n\\\\n## Functional Requirements\\\\n1. Task submission with priority levels\\\\n2. Dynamic worker node registration and management\\\\n3. Automatic task redistribution on worker failure\\\\n4. Configurable retry mechanisms\\\\n5. Real-time task status tracking\\\\n6. Support for different task types (compute, I/O, network)\\\\n\\\\n## Non-functional Requirements\\\\n1. Horizontal scalability to support 100+ worker nodes\\\\n2. Low latency task scheduling (<50ms)\\\\n3. 99.9% task completion reliability\\\\n4. Secure communication between master and worker nodes\\\\n5. Minimal resource overhead\\\\n6. Support for containerized and cloud-native deployments\\\\n\\\\n## Success Metrics\\\\n1. Task completion rate > 99.5%\\\\n2. Average task scheduling latency < 100ms\\\\n3. System can handle 1000+ concurrent tasks\\\\n4. Automatic recovery from worker node failures within 5 seconds\\\\n5. Less than 1% performance degradation under high load\\\\n', 'design': '\\\\n## System Architecture\\\\n- Master Node (Coordinator)\\\\n  - Task Queue Manager\\\\n  - Worker Registry\\\\n  - Health Monitoring Service\\\\n- Worker Nodes\\\\n  - Task Executor\\\\n  - Local Task Queue\\\\n  - Health Reporting Agent\\\\n\\\\nArchitecture Pattern: Distributed Master-Worker with Pub/Sub Communication\\\\n\\\\n## API Design\\\\n1. Task Submission Endpoint\\\\n- POST /tasks\\\\n  Request Body: {\\\\n    task_id: UUID,\\\\n    priority: int,\\\\n    type: string,\\\\n    payload: JSON,\\\\n    max_retries: int\\\\n  }\\\\n\\\\n2. Worker Registration\\\\n- POST /workers/register\\\\n  Request Body: {\\\\n    worker_id: UUID,\\\\n    capabilities: [string],\\\\n    resources: {\\\\n      cpu: float,\\\\n      memory: float\\\\n    }\\\\n  }\\\\n\\\\n## Data Models\\\\n1. Task\\\\n- task_id: UUID\\\\n- status: enum (PENDING, RUNNING, COMPLETED, FAILED)\\\\n- priority: int\\\\n- type: string\\\\n- payload: JSON\\\\n- created_at: timestamp\\\\n- updated_at: timestamp\\\\n- retry_count: int\\\\n\\\\n2. Worker\\\\n- worker_id: UUID\\\\n- status: enum (ACTIVE, INACTIVE)\\\\n- capabilities: [string]\\\\n- last_heartbeat: timestamp\\\\n\\\\n## Technology Stack\\\\n- Language: Python 3.9+\\\\n- Concurrency: asyncio, multiprocessing\\\\n- Message Broker: Apache Kafka\\\\n- Service Discovery: Consul\\\\n- Database: Redis (for task tracking)\\\\n- Containerization: Docker, Kubernetes\\\\n- Monitoring: Prometheus, Grafana\\\\n\\\\n## Security Considerations\\\\n1. JWT-based authentication\\\\n2. TLS encryption for all communications\\\\n3. Role-based access control\\\\n4. Secure worker node registration with pre-shared keys\\\\n5. Input validation and sanitization\\\\n\\\\n## Scalability Plan\\\\n1. Horizontal scaling of worker nodes\\\\n2. Sharded task queues\\\\n3. Stateless master node design\\\\n4. Caching with Redis\\\\n5. Event-driven architecture for loose coupling\\\\n'}"], "filter": "multi_turn_responses", "metrics": ["overall_multi_turn_score", "phase_completion_score", "integrated_prd_completeness_score", "integrated_prd_clarity_score", "integrated_design_coherence_score", "integrated_design_feasibility_score", "integrated_code_functionality_score", "integrated_code_structure_score", "integrated_code_test_coverage_score", "integrated_phase_consistency_score", "integrated_information_flow_score"], "doc_hash": "cfc6b20b625eab1d5fa4171b2642c18e2c141897a5477d931599acbb3f5493e4", "prompt_hash": "f198e1ede4c3c71e6db5fbefe1996daa42d1aa653f7d9187b88398289cf491c7", "target_hash": "cd13041b88315914d3e6ac50c4911ed356fa04815525cb63a6234ce3ed5948c8", "overall_multi_turn_score": 1.0, "phase_completion_score": 1.0, "integrated_prd_completeness_score": 1.0, "integrated_prd_clarity_score": 1.0, "integrated_design_coherence_score": 1.0, "integrated_design_feasibility_score": 1.0, "integrated_code_functionality_score": 1.0, "integrated_code_structure_score": 1.0, "integrated_code_test_coverage_score": 1.0, "integrated_phase_consistency_score": 1.0, "integrated_information_flow_score": 1.0}
