# AI Evaluation Engine å®Œæ•´ä½¿ç”¨æŒ‡å—

## ğŸš€ APIæœåŠ¡å™¨ä½¿ç”¨

### å¯åŠ¨APIæœåŠ¡å™¨

#### æ–¹æ³•1ï¼šçœŸå®è¯„ä¼°æœåŠ¡å™¨ï¼ˆæ¨èï¼‰
```bash
# å¯åŠ¨çœŸå®çš„APIæœåŠ¡å™¨ï¼Œæ”¯æŒå®é™…çš„lm-evalä»»åŠ¡æ‰§è¡Œ
python real_api_server.py
```

#### æ–¹æ³•2ï¼šç®€åŒ–æµ‹è¯•æœåŠ¡å™¨
```bash
# å¯åŠ¨ç®€åŒ–ç‰ˆæœåŠ¡å™¨ï¼Œä»…ç”¨äºAPIæ¥å£æµ‹è¯•
python simple_api_server.py
```

### APIä½¿ç”¨æµç¨‹

#### 1. å¥åº·æ£€æŸ¥
```bash
curl -X GET http://localhost:8000/health
```

#### 2. ç”¨æˆ·ç™»å½•è·å–è®¿é—®ä»¤ç‰Œ
```bash
curl -X POST http://localhost:8000/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username": "admin", "password": "admin123"}'
```

#### 3. è·å–å¯ç”¨ä»»åŠ¡å’Œæ¨¡å‹
```bash
# è·å–ä»»åŠ¡åˆ—è¡¨
curl -X GET "http://localhost:8000/tasks?limit=10" \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"

# è·å–æ¨¡å‹åˆ—è¡¨
curl -X GET http://localhost:8000/models \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

#### 4. åˆ›å»ºå¹¶æ‰§è¡Œlm-evalä»»åŠ¡
```bash
curl -X POST http://localhost:8000/evaluations \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "dummy",
    "task_ids": ["single_turn_scenarios_function_generation"],
    "configuration": {
      "limit": 3,
      "temperature": 0.7
    },
    "metadata": {
      "experiment_name": "api_demo"
    }
  }'
```

#### 5. ç›‘æ§è¯„ä¼°è¿›åº¦
```bash
curl -X GET http://localhost:8000/evaluations/EVALUATION_ID \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

#### 6. è·å–è¯„ä¼°ç»“æœ
```bash
curl -X GET "http://localhost:8000/results/EVALUATION_ID?include_details=true" \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

### è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

#### Python APIå®¢æˆ·ç«¯æµ‹è¯•
```bash
# è¿è¡Œå®Œæ•´çš„APIåŠŸèƒ½æµ‹è¯•
python test_real_lm_eval.py
```

#### Bashè„šæœ¬æµ‹è¯•
```bash
# è¿è¡Œcurlå‘½ä»¤æµ‹è¯•
chmod +x curl_test_examples.sh
./curl_test_examples.sh
```

### å¯ç”¨çš„çœŸå®ä»»åŠ¡

APIæœåŠ¡å™¨æ”¯æŒä»¥ä¸‹çœŸå®çš„lm-evalä»»åŠ¡ï¼š
- `single_turn_scenarios_function_generation` - å‡½æ•°ç”Ÿæˆ
- `single_turn_scenarios_code_completion` - ä»£ç è¡¥å…¨
- `single_turn_scenarios_bug_fix` - é”™è¯¯ä¿®å¤
- `single_turn_scenarios_algorithm_implementation` - ç®—æ³•å®ç°
- `single_turn_scenarios_api_design` - APIè®¾è®¡
- æ›´å¤šä»»åŠ¡è¯·é€šè¿‡APIæŸ¥è¯¢

### æ”¯æŒçš„æ¨¡å‹

- `dummy` - æµ‹è¯•æ¨¡å‹ï¼ˆæ— éœ€APIå¯†é’¥ï¼‰
- `claude-local` - Claude 3 Haikuï¼ˆéœ€è¦ANTHROPIC_API_KEYï¼‰
- `openai-completions` - GPT-3.5 Turboï¼ˆéœ€è¦OPENAI_API_KEYï¼‰
- `deepseek` - DeepSeek Coderï¼ˆéœ€è¦DEEPSEEK_API_KEYï¼‰

## ğŸ¯ æµ‹è¯•å¥—ä»¶è¿è¡Œ

### è¿è¡Œå…¨éƒ¨æµ‹è¯•
```bash
python -m pytest evaluation_engine/tests/ -v
```

### æŒ‰ç›®å½•è¿è¡Œ

| æµ‹è¯•ç±»åˆ« | å‘½ä»¤ | è¯´æ˜ |
|---------|------|------|
| æ ¸å¿ƒå¼•æ“ | `pytest evaluation_engine/tests/core_engines/ -v` | åˆ†æã€æŒ‡æ ‡ã€æç¤ºã€å¯è§†åŒ–å¼•æ“ |
| APIé›†æˆ | `pytest evaluation_engine/tests/api_integration/ -v` | APIç½‘å…³å’Œç³»ç»Ÿé›†æˆæµ‹è¯• |
| å®‰å…¨æµ‹è¯• | `pytest evaluation_engine/tests/security/ -v` | å®‰å…¨æ¡†æ¶å’Œåˆè§„æµ‹è¯• |
| åˆ†æå·¥å…· | `pytest evaluation_engine/tests/analysis_tools/ -v` | æ•°æ®åˆ†æå·¥å…·æµ‹è¯• |
| ä¸“é¡¹åŠŸèƒ½ | `pytest evaluation_engine/tests/specialized/ -v` | æ¨¡å‹é…ç½®å’Œç‰¹æ®ŠåŠŸèƒ½æµ‹è¯• |

## ğŸ” å•ä¸ªæµ‹è¯•æ–‡ä»¶

| æ–‡ä»¶ | å¿«é€Ÿè¿è¡Œ | åŠŸèƒ½ |
|------|----------|------|
| core_engines/test_analysis_engine.py | `python evaluation_engine/tests/core_engines/test_analysis_engine.py` | è¶‹åŠ¿åˆ†æã€å¼‚å¸¸æ£€æµ‹ |
| core_engines/test_metrics_engine.py | `python evaluation_engine/tests/core_engines/test_metrics_engine.py` | NLPæŒ‡æ ‡è®¡ç®— |
| api_integration/test_api_minimal.py | `python evaluation_engine/tests/api_integration/test_api_minimal.py` | APIåŸºç¡€éªŒè¯ |
| api_integration/test_integration.py | `python evaluation_engine/tests/api_integration/test_integration.py` | lm-evalé›†æˆ |
| security/test_security_framework.py | `pytest evaluation_engine/tests/security/test_security_framework.py -v` | å®Œæ•´å®‰å…¨æµ‹è¯• |

## âš¡ å¿«é€Ÿè¯Šæ–­

### æ£€æŸ¥ç¯å¢ƒ
```bash
python -c "import evaluation_engine; print('âœ… å¯¼å…¥æˆåŠŸ')"
```

### éªŒè¯ä¾èµ–
```bash
pip install -r requirements_api.txt
```

### ç”ŸæˆæŠ¥å‘Š
```bash
pytest evaluation_engine/tests/ --html=report.html
```

## ğŸš¨ å¸¸è§é”™è¯¯è§£å†³

| é”™è¯¯ | è§£å†³æ–¹æ¡ˆ |
|------|----------|
| `ModuleNotFoundError` | `export PYTHONPATH="${PYTHONPATH}:."` |
| `ImportError` | `pip install -r requirements_api.txt` |
| ç«¯å£å ç”¨ | æ£€æŸ¥å¹¶é‡Šæ”¾ç›¸å…³ç«¯å£ |
| æƒé™é”™è¯¯ | ç¡®ä¿æ–‡ä»¶è¯»å†™æƒé™ |

## ğŸ“Š æµ‹è¯•è¦†ç›–

```bash
# å®‰è£…è¦†ç›–ç‡å·¥å…·
pip install pytest-cov

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest evaluation_engine/tests/ --cov=evaluation_engine --cov-report=term-missing
```

## ğŸ”§ APIé…ç½®å’Œæ•…éšœæ’é™¤

### ç¯å¢ƒå˜é‡é…ç½®
```bash
# å¯é€‰ï¼šé…ç½®AIæ¨¡å‹APIå¯†é’¥
export ANTHROPIC_API_KEY="your_anthropic_key"
export OPENAI_API_KEY="your_openai_key"
export DEEPSEEK_API_KEY="your_deepseek_key"
export DASHSCOPE_API_KEY="your_dashscope_key"
```

### ä¾èµ–å®‰è£…
```bash
# APIæœåŠ¡å™¨ä¾èµ–
pip install fastapi uvicorn pydantic PyJWT python-multipart

# lm-evalæ¡†æ¶
pip install lm-eval
```

### å¸¸è§APIé—®é¢˜

| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|----------|
| ç«¯å£8000è¢«å ç”¨ | `pkill -f "python.*api_server.py"` ç„¶åé‡å¯ |
| 401è®¤è¯å¤±è´¥ | æ£€æŸ¥è®¿é—®ä»¤ç‰Œæ˜¯å¦è¿‡æœŸï¼Œé‡æ–°ç™»å½• |
| 404ä»»åŠ¡ä¸å­˜åœ¨ | é€šè¿‡`/tasks`ç«¯ç‚¹æŸ¥çœ‹å¯ç”¨ä»»åŠ¡åˆ—è¡¨ |
| 500æœåŠ¡å™¨é”™è¯¯ | æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—ï¼Œç¡®è®¤lm-evalç¯å¢ƒæ­£å¸¸ |

### APIæ–‡æ¡£è®¿é—®
- å¯åŠ¨æœåŠ¡å™¨åè®¿é—®ï¼šhttp://localhost:8000/docs
- äº¤äº’å¼APIæµ‹è¯•ç•Œé¢ï¼Œæ”¯æŒåœ¨çº¿æµ‹è¯•æ‰€æœ‰ç«¯ç‚¹

### æ€§èƒ½ä¼˜åŒ–å»ºè®®
- ä½¿ç”¨`limit`å‚æ•°æ§åˆ¶è¯„ä¼°æ ·æœ¬æ•°é‡
- å¯¹äºå¤§è§„æ¨¡è¯„ä¼°ï¼Œå»ºè®®ä½¿ç”¨å¼‚æ­¥æ–¹å¼ç›‘æ§è¿›åº¦
- ç”Ÿäº§ç¯å¢ƒå»ºè®®é…ç½®é€‚å½“çš„é€Ÿç‡é™åˆ¶å’Œè¶…æ—¶è®¾ç½®

## ğŸ“š å®Œæ•´æ–‡æ¡£

è¯¦ç»†çš„APIä½¿ç”¨æŒ‡å—è¯·å‚è€ƒï¼š
- `API_USAGE_COMPLETE_GUIDE.md` - å®Œæ•´çš„APIä½¿ç”¨æŒ‡å—
- `evaluation_engine/docs/api_usage_guide.md` - APIæŠ€æœ¯æ–‡æ¡£
- åœ¨çº¿APIæ–‡æ¡£ï¼šhttp://localhost:8000/docsï¼ˆæœåŠ¡å™¨å¯åŠ¨åï¼‰