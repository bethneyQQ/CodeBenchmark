# AI Evaluation Engine å®‰è£…å’Œä½¿ç”¨æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—æä¾›äº†AI Evaluation Engineçš„å®Œæ•´å®‰è£…ã€é…ç½®å’Œä½¿ç”¨æµç¨‹ã€‚æ‰€æœ‰å‘½ä»¤éƒ½ç»è¿‡å®é™…æµ‹è¯•éªŒè¯ï¼Œç¡®ä¿å¯ä»¥æ­£å¸¸è¿è¡Œå¹¶äº§ç”Ÿæœ‰æ•ˆçš„åˆ†ææŠ¥å‘Šã€‚

## ğŸ“ æ–‡ä»¶è¯´æ˜

### å®‰è£…å’ŒéªŒè¯æ–‡ä»¶
- **`quick_setup.sh`** - ä¸€é”®å®‰è£…è„šæœ¬ï¼Œè‡ªåŠ¨è®¾ç½®å®Œæ•´ç¯å¢ƒ
- **`quick_verify.py`** - å®‰è£…éªŒè¯è„šæœ¬ï¼Œæ£€æŸ¥æ‰€æœ‰ç»„ä»¶æ˜¯å¦æ­£å¸¸
- **`demo_quick_start.py`** - å¿«é€Ÿæ¼”ç¤ºè„šæœ¬ï¼Œå±•ç¤ºå®Œæ•´è¯„ä¼°æµç¨‹

### ä½¿ç”¨æ–‡æ¡£
- **`user_menu.md`** - å®Œæ•´ç”¨æˆ·èœå•ï¼ŒåŒ…å«æ‰€æœ‰å¯ç”¨å‘½ä»¤
- **`README.md`** - æ–‡æ¡£ç»“æ„è¯´æ˜
- **`INSTALLATION_GUIDE.md`** - æœ¬å®‰è£…æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¬¬ä¸€æ­¥ï¼šè¿è¡Œä¸€é”®å®‰è£…
```bash
# ç»™è„šæœ¬æ·»åŠ æ‰§è¡Œæƒé™ï¼ˆå¦‚æœéœ€è¦ï¼‰
chmod +x evaluation_engine/docs/quick_setup.sh

# è¿è¡Œä¸€é”®å®‰è£…
bash evaluation_engine/docs/quick_setup.sh
```

å®‰è£…è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆéœ€è¦3.9+ï¼‰
- æ£€æŸ¥Dockerå¯ç”¨æ€§
- åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
- å®‰è£…æ‰€æœ‰ä¾èµ–åŒ…
- è®¾ç½®é…ç½®æ–‡ä»¶
- åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
- è¿è¡ŒåŸºç¡€æµ‹è¯•

### ç¬¬äºŒæ­¥ï¼šé…ç½®APIå¯†é’¥
ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œæ·»åŠ æ‚¨çš„APIå¯†é’¥ï¼š
```bash
# ç¼–è¾‘ç¯å¢ƒé…ç½®æ–‡ä»¶
nano .env

# æˆ–è€…ç›´æ¥è®¾ç½®ç¯å¢ƒå˜é‡
export ANTHROPIC_API_KEY="your_anthropic_key_here"
export OPENAI_API_KEY="your_openai_key_here"
export DEEPSEEK_API_KEY="your_deepseek_key_here"
export DASHSCOPE_API_KEY="your_dashscope_key_here"
```

### ç¬¬ä¸‰æ­¥ï¼šéªŒè¯å®‰è£…
```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# è¿è¡ŒéªŒè¯è„šæœ¬
python evaluation_engine/docs/quick_verify.py
```

éªŒè¯è„šæœ¬ä¼šæ£€æŸ¥ï¼š
- Pythonç¯å¢ƒå’Œè™šæ‹Ÿç¯å¢ƒ
- å…³é”®ä¾èµ–åŒ…å®‰è£…
- APIå¯†é’¥é…ç½®
- ä»»åŠ¡æ³¨å†ŒçŠ¶æ€
- åŸºç¡€åŠŸèƒ½æµ‹è¯•
- åˆ†æå·¥å…·å¯ç”¨æ€§

### ç¬¬å››æ­¥ï¼šè¿è¡Œå¿«é€Ÿæ¼”ç¤º
```bash
# è¿è¡Œå¿«é€Ÿæ¼”ç¤º
python evaluation_engine/docs/demo_quick_start.py
```

æ¼”ç¤ºè„šæœ¬ä¼šï¼š
- è‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„æ¨¡å‹
- è¿è¡Œå®é™…çš„è¯„ä¼°ä»»åŠ¡
- ç”Ÿæˆç»“æœæ–‡ä»¶
- å±•ç¤ºåˆ†æå·¥å…·åŠŸèƒ½
- æ˜¾ç¤ºåç»­ä½¿ç”¨æ­¥éª¤

## ğŸ“Š éªŒè¯æˆåŠŸæ ‡å‡†

### å®‰è£…æˆåŠŸæ ‡å¿—
- âœ… Python 3.9+ ç‰ˆæœ¬æ£€æŸ¥é€šè¿‡
- âœ… è™šæ‹Ÿç¯å¢ƒåˆ›å»ºæˆåŠŸ
- âœ… æ‰€æœ‰ä¾èµ–åŒ…å®‰è£…å®Œæˆ
- âœ… é…ç½®æ–‡ä»¶åˆ›å»ºæˆåŠŸ
- âœ… åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡

### éªŒè¯æˆåŠŸæ ‡å¿—
- âœ… è‡³å°‘1ä¸ªAPIå¯†é’¥é…ç½®æˆåŠŸ
- âœ… æ‰¾åˆ°18ä¸ªsingle_turn_scenariosä»»åŠ¡
- âœ… Dummyæ¨¡å‹æµ‹è¯•é€šè¿‡
- âœ… APIæ¨¡å‹æµ‹è¯•é€šè¿‡ï¼ˆå¦‚æœæœ‰APIå¯†é’¥ï¼‰
- âœ… 4ä¸ªåˆ†æå·¥å…·å…¨éƒ¨å¯ç”¨

### æ¼”ç¤ºæˆåŠŸæ ‡å¿—
- âœ… è¯„ä¼°ä»»åŠ¡æˆåŠŸè¿è¡Œ
- âœ… ç”Ÿæˆç»“æœæ–‡ä»¶ï¼ˆJSONæ ¼å¼ï¼‰
- âœ… ç”Ÿæˆæ ·æœ¬æ–‡ä»¶ï¼ˆJSONLæ ¼å¼ï¼‰
- âœ… åˆ†æå·¥å…·æˆåŠŸåˆå§‹åŒ–
- âœ… æ˜¾ç¤ºç»“æœæ‘˜è¦å’Œæ ·æœ¬ç¤ºä¾‹

## ğŸ”§ å®é™…å¯ç”¨çš„å‘½ä»¤

### åŸºç¡€è¯„ä¼°å‘½ä»¤ï¼ˆå·²æµ‹è¯•ï¼‰
```bash
# å‡½æ•°ç”Ÿæˆä»»åŠ¡
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_function_generation --limit 5 \
  --output_path results/function_gen_test.json

# ä»£ç è¡¥å…¨ä»»åŠ¡
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_code_completion --limit 5 \
  --output_path results/code_completion_test.json

# æ‰¹é‡ä»»åŠ¡è¯„ä¼°
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_function_generation,single_turn_scenarios_code_completion \
  --limit 5 --output_path results/batch_test.json --log_samples
```

### åˆ†æå·¥å…·å‘½ä»¤ï¼ˆå·²æµ‹è¯•ï¼‰
```bash
# æµ‹è¯•åˆ†æå·¥å…·
python evaluation_engine/tests/analysis_tools/test_analysis_tools.py

# æ¼”ç¤ºåˆ†æå·¥å…·
python demo_analysis_tools.py

# è¿è¡Œå®Œæ•´æ¼”ç¤º
python demo_single_turn_scenarios.py
```

### æµ‹è¯•å¥—ä»¶å‘½ä»¤ï¼ˆå·²æµ‹è¯•ï¼‰
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest evaluation_engine/tests/ -v

# è¿è¡Œåˆ†æå·¥å…·æµ‹è¯•
python -m pytest evaluation_engine/tests/analysis_tools/ -v

# è¿è¡Œä¸“é¡¹åŠŸèƒ½æµ‹è¯•
python -m pytest evaluation_engine/tests/specialized/ -v
```

## ğŸ“ˆ å®é™…è¾“å‡ºç¤ºä¾‹

### è¯„ä¼°ç»“æœæ–‡ä»¶ç»“æ„
```json
{
  "results": {
    "single_turn_scenarios_function_generation": {
      "alias": "single_turn_scenarios_function_generation",
      "bypass,extract_code": 999,
      "bypass_stderr,extract_code": "N/A"
    }
  },
  "config": {
    "model": "claude-local",
    "model_args": "model=claude-3-haiku-20240307",
    "batch_size": 1,
    "limit": 5.0
  },
  "versions": {
    "single_turn_scenarios_function_generation": 1.0
  }
}
```

### æ ·æœ¬æ–‡ä»¶ç»“æ„
```json
{"doc": {"id": "func_001", "prompt": "Write a function to..."}, "resps": [["def solution():\n    # Generated code\n    pass"]], "filtered_resps": ["def solution():\n    # Generated code\n    pass"]}
```

### åˆ†æå·¥å…·è¾“å‡º
```
ğŸ” åˆ†æå·¥å…·æµ‹è¯•å®Œæˆï¼Œ4/4 ä¸ªå·¥å…·å¯ç”¨
âœ… ScenarioAnalyzer - åˆå§‹åŒ–æˆåŠŸ
âœ… ModelComparator - åˆå§‹åŒ–æˆåŠŸ  
âœ… ContextAnalyzer - åˆå§‹åŒ–æˆåŠŸ
âœ… ReportGenerator - åˆå§‹åŒ–æˆåŠŸ
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. Pythonç‰ˆæœ¬é—®é¢˜
```bash
# é”™è¯¯ï¼šPythonç‰ˆæœ¬è¿‡ä½
# è§£å†³ï¼šå®‰è£…Python 3.9+
brew install python@3.9  # macOS
sudo apt install python3.9  # Ubuntu
```

#### 2. è™šæ‹Ÿç¯å¢ƒé—®é¢˜
```bash
# é”™è¯¯ï¼šè™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥
# è§£å†³ï¼šæ‰‹åŠ¨åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip
```

#### 3. ä¾èµ–å®‰è£…é—®é¢˜
```bash
# é”™è¯¯ï¼šä¾èµ–å®‰è£…å¤±è´¥
# è§£å†³ï¼šæ‰‹åŠ¨å®‰è£…ä¾èµ–
pip install -e ".[dev,api,testing,evaluation_engine]"
pip install -r requirements_api.txt
```

#### 4. ä»»åŠ¡æœªæ‰¾åˆ°
```bash
# é”™è¯¯ï¼šTask 'single_turn_scenarios_function_generation' not found
# è§£å†³ï¼šæ£€æŸ¥å½“å‰ç›®å½•å’Œä»»åŠ¡æ³¨å†Œ
pwd  # ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•
python -m lm_eval --tasks list | grep single_turn_scenarios
```

#### 5. APIå¯†é’¥é—®é¢˜
```bash
# é”™è¯¯ï¼šAPI key not found
# è§£å†³ï¼šæ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®
echo $ANTHROPIC_API_KEY
export ANTHROPIC_API_KEY="your_key_here"
```

#### 6. è¾“å‡ºè·¯å¾„é—®é¢˜
```bash
# é”™è¯¯ï¼šSpecify --output_path if providing --predict_only
# è§£å†³ï¼šæ·»åŠ è¾“å‡ºè·¯å¾„å‚æ•°
python -m lm_eval --model dummy --tasks single_turn_scenarios_function_generation \
  --limit 1 --predict_only --output_path results/test
```

### è°ƒè¯•å‘½ä»¤
```bash
# è¯¦ç»†è°ƒè¯•æ¨¡å¼
python -m lm_eval --model claude-local --tasks single_turn_scenarios_function_generation \
  --limit 1 --verbosity DEBUG --output_path results/debug_test

# æ£€æŸ¥ä»»åŠ¡é…ç½®
python -c "
from lm_eval.tasks import TaskManager
tm = TaskManager()
task = tm.load_task_or_group('single_turn_scenarios_function_generation')
print(list(task.keys()))
"

# æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§
python -c "
from lm_eval.models import get_model
model = get_model('claude-local')
print('Model loaded successfully')
"
```

## ğŸ“‹ å®Œæ•´å·¥ä½œæµç¨‹

### æ ‡å‡†ä½¿ç”¨æµç¨‹
1. **å®‰è£…**: `bash evaluation_engine/docs/quick_setup.sh`
2. **é…ç½®**: ç¼–è¾‘ `.env` æ–‡ä»¶æ·»åŠ APIå¯†é’¥
3. **éªŒè¯**: `python evaluation_engine/docs/quick_verify.py`
4. **æ¼”ç¤º**: `python evaluation_engine/docs/demo_quick_start.py`
5. **ä½¿ç”¨**: å‚è€ƒ `user_menu.md` ä¸­çš„è¯¦ç»†å‘½ä»¤

### å¼€å‘æµ‹è¯•æµç¨‹
1. **è¿è¡Œæµ‹è¯•**: `python -m pytest evaluation_engine/tests/ -v`
2. **åˆ†æå·¥å…·**: `python demo_analysis_tools.py`
3. **å®Œæ•´æ¼”ç¤º**: `python demo_single_turn_scenarios.py`
4. **è‡ªå®šä¹‰è¯„ä¼°**: æŒ‰éœ€ä¿®æ”¹å‚æ•°å’Œä»»åŠ¡

## ğŸ“ è·å–å¸®åŠ©

### æ–‡æ¡£èµ„æº
- `user_menu.md` - å®Œæ•´å‘½ä»¤å‚è€ƒ
- `evaluation_engine/tests/README.md` - æµ‹è¯•å¥—ä»¶è¯´æ˜
- `evaluation_engine/tests/analysis_tools/USAGE.md` - åˆ†æå·¥å…·è¯¦ç»†è¯´æ˜

### åœ¨çº¿å¸®åŠ©
```bash
python -m lm_eval --help
python -m lm_eval --tasks list
python -m lm_eval --model list
```

### ç¤¾åŒºæ”¯æŒ
- æŸ¥çœ‹é¡¹ç›®README.md
- æ£€æŸ¥ç°æœ‰çš„issueå’Œæ–‡æ¡£
- è¿è¡Œæµ‹è¯•å¥—ä»¶ç¡®è®¤åŠŸèƒ½çŠ¶æ€

---

**é‡è¦æç¤º**: æœ¬æŒ‡å—ä¸­çš„æ‰€æœ‰å‘½ä»¤å’Œç¤ºä¾‹éƒ½ç»è¿‡å®é™…æµ‹è¯•éªŒè¯ï¼Œåœ¨æ­£ç¡®å®‰è£…å’Œé…ç½®çš„ç¯å¢ƒä¸­å¯ä»¥æ­£å¸¸è¿è¡Œå¹¶äº§ç”Ÿæœ‰æ•ˆçš„åˆ†ææŠ¥å‘Šã€‚å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æŒ‰ç…§æ•…éšœæ’é™¤éƒ¨åˆ†çš„å»ºè®®è¿›è¡Œæ£€æŸ¥å’Œä¿®å¤ã€‚