# AI Evaluation Engine ç”¨æˆ·èœå•

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè®¾ç½®
```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# è®¾ç½®APIå¯†é’¥ï¼ˆé€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªï¼‰
export ANTHROPIC_API_KEY="your_anthropic_key_here"
export OPENAI_API_KEY="your_openai_key_here"
export DEEPSEEK_API_KEY="your_deepseek_key_here"
export DASHSCOPE_API_KEY="your_dashscope_key_here"
```

### 2. éªŒè¯å®‰è£…
```bash
# æµ‹è¯•åŸºç¡€åŠŸèƒ½
python evaluation_engine/tests/specialized/test_single_turn_simple.py

# æµ‹è¯•lm-evalé›†æˆ
python -m lm_eval --model dummy --tasks single_turn_scenarios_function_generation --limit 1 --predict_only
```

## ğŸ“Š æ ¸å¿ƒè¯„ä¼°åŠŸèƒ½

### å•è½®åœºæ™¯è¯„ä¼°

#### åŸºç¡€åŠŸèƒ½æµ‹è¯•
```bash
# å‡½æ•°ç”Ÿæˆä»»åŠ¡ï¼ˆæœ€å¸¸ç”¨ï¼‰
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_function_generation --limit 5 --output_path results/function_gen_test.json

# ä»£ç è¡¥å…¨ä»»åŠ¡
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_code_completion --limit 5 --output_path results/code_completion_test.json

# Bugä¿®å¤ä»»åŠ¡
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_bug_fix --limit 5 --output_path results/bug_fix_test.json
```

#### æ‰¹é‡è¯„ä¼°
```bash
# è¿è¡Œå¤šä¸ªç›¸å…³ä»»åŠ¡
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_function_generation,single_turn_scenarios_code_completion \
  --limit 5 --output_path results/batch_test.json

# è¿è¡Œæ‰€æœ‰Pythonç›¸å…³ä»»åŠ¡
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_python --limit 10 --output_path results/python_all_test.json
```

#### å®Œæ•´éªŒè¯å¥—ä»¶
```bash
# è¿è¡Œå®Œæ•´éªŒè¯ï¼ˆå·²æµ‹è¯•å¯ç”¨ï¼‰
python demo_single_turn_scenarios.py
```

### ä¸åŒæ¨¡å‹æµ‹è¯•

#### Claudeæ¨¡å‹
```bash
# Claude Haikuï¼ˆå¿«é€Ÿï¼Œæˆæœ¬ä½ï¼‰
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_function_generation --limit 3

# Claude Sonnetï¼ˆå¹³è¡¡æ€§èƒ½ï¼‰
python -m lm_eval --model claude-local --model_args model=claude-3-5-sonnet-20241022 \
  --tasks single_turn_scenarios_function_generation --limit 3
```

#### OpenAIæ¨¡å‹
```bash
# GPT-4 Turbo
python -m lm_eval --model openai-completions --model_args model=gpt-4-turbo \
  --tasks single_turn_scenarios_function_generation --limit 3

# GPT-3.5 Turbo
python -m lm_eval --model openai-completions --model_args model=gpt-3.5-turbo \
  --tasks single_turn_scenarios_function_generation --limit 3
```

#### DeepSeekæ¨¡å‹
```bash
# DeepSeek Coder
python -m lm_eval --model deepseek --model_args model=deepseek-coder \
  --tasks single_turn_scenarios_function_generation --limit 3
```

#### é€šä¹‰åƒé—®æ¨¡å‹
```bash
# Qwen Plus
python -m lm_eval --model dashscope --model_args model=qwen-plus \
  --tasks single_turn_scenarios_function_generation --limit 3
```

## ğŸ“ˆ åˆ†æå·¥å…·ä½¿ç”¨

### è¿è¡Œåˆ†æå·¥å…·
```bash
# æµ‹è¯•åˆ†æå·¥å…·ï¼ˆéœ€è¦å…ˆæœ‰ç»“æœæ–‡ä»¶ï¼‰
python evaluation_engine/tests/analysis_tools/test_analysis_tools.py

# æ¼”ç¤ºåˆ†æå·¥å…·åŠŸèƒ½
python demo_analysis_tools.py
```

### ç”Ÿæˆåˆ†ææŠ¥å‘Š
```bash
# ç¡®ä¿æœ‰ç»“æœæ–‡ä»¶åè¿è¡Œ
python -c "
import sys
sys.path.append('lm_eval/tasks/single_turn_scenarios/analysis_tools')
from scenario_analysis import ScenarioAnalyzer
from generate_report import ReportGenerator
import json
import glob

# åŠ è½½ç»“æœæ–‡ä»¶
result_files = glob.glob('results/validation_*.json')
if result_files:
    sample_data = []
    for file in result_files[:5]:
        with open(file, 'r') as f:
            data = json.load(f)
            if 'results' in data:
                for task_name, task_results in data['results'].items():
                    sample_data.append({
                        'task': task_name,
                        'model': data.get('config', {}).get('model', 'unknown'),
                        'scenario': task_name.replace('single_turn_scenarios_', ''),
                        'metrics': task_results
                    })
    
    if sample_data:
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        analyzer = ScenarioAnalyzer(sample_data)
        generator = ReportGenerator(sample_data)
        print(f'åˆ†æäº† {len(sample_data)} ä¸ªç»“æœ')
        print('åˆ†æå·¥å…·å·²å‡†å¤‡å°±ç»ª')
    else:
        print('æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç»“æœæ•°æ®')
else:
    print('æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œè¯„ä¼°')
"
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### è‡ªå®šä¹‰æ•°æ®é›†è¯„ä¼°
```bash
# ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_function_generation \
  --metadata '{"dataset_path": "my_custom_data.jsonl"}' --limit 5
```

### å‚æ•°è°ƒä¼˜
```bash
# è°ƒæ•´æ¸©åº¦å‚æ•°
python -m lm_eval --model claude-local \
  --model_args model=claude-3-haiku-20240307,temperature=0.7 \
  --tasks single_turn_scenarios_function_generation --limit 3

# è°ƒæ•´æœ€å¤§tokenæ•°
python -m lm_eval --model claude-local \
  --model_args model=claude-3-haiku-20240307,max_tokens=1024 \
  --tasks single_turn_scenarios_function_generation --limit 3
```

### è¯¦ç»†æ—¥å¿—å’Œè°ƒè¯•
```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_function_generation --limit 1 \
  --log_samples --verbosity DEBUG

# ä»…é¢„æµ‹æ¨¡å¼ï¼ˆè·³è¿‡å¤æ‚æŒ‡æ ‡è®¡ç®—ï¼‰
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_function_generation --limit 3 --predict_only
```

## ğŸ“Š ç»“æœæŸ¥çœ‹å’Œåˆ†æ

### æŸ¥çœ‹ç»“æœæ–‡ä»¶
```bash
# åˆ—å‡ºæ‰€æœ‰ç»“æœæ–‡ä»¶
ls -la results/

# æŸ¥çœ‹æœ€æ–°çš„ç»“æœæ–‡ä»¶
ls -t results/*.json | head -1 | xargs cat | jq '.'

# æŸ¥çœ‹æ ·æœ¬è¾“å‡º
ls -t results/samples_*.jsonl | head -1 | xargs head -5
```

### ç»“æœæ–‡ä»¶ç»“æ„
```bash
# ä¸»è¦ç»“æœæ–‡ä»¶åŒ…å«ï¼š
# - results: ä»»åŠ¡æŒ‡æ ‡å’Œåˆ†æ•°
# - configs: ä»»åŠ¡é…ç½®ä¿¡æ¯
# - versions: ä»»åŠ¡ç‰ˆæœ¬ä¿¡æ¯
# - config: æ¨¡å‹å’Œè¿è¡Œé…ç½®

# æ ·æœ¬æ–‡ä»¶åŒ…å«ï¼š
# - æ¯ä¸ªæµ‹è¯•æ ·æœ¬çš„è¾“å…¥ã€è¾“å‡ºå’Œè¯¦ç»†ä¿¡æ¯
```

## ğŸ§ª æµ‹è¯•å¥—ä»¶

### è¿è¡Œæ‰€æœ‰æµ‹è¯•
```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
python -m pytest evaluation_engine/tests/ -v

# è¿è¡Œç‰¹å®šç±»åˆ«æµ‹è¯•
python -m pytest evaluation_engine/tests/analysis_tools/ -v
python -m pytest evaluation_engine/tests/specialized/ -v
python -m pytest evaluation_engine/tests/core_engines/ -v
```

### å•ç‹¬æµ‹è¯•ç»„ä»¶
```bash
# æµ‹è¯•åˆ†æå¼•æ“
python evaluation_engine/tests/core_engines/test_analysis_engine.py

# æµ‹è¯•æŒ‡æ ‡å¼•æ“
python evaluation_engine/tests/core_engines/test_metrics_engine.py

# æµ‹è¯•APIé›†æˆ
python evaluation_engine/tests/api_integration/test_integration.py
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜è§£å†³
```bash
# æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æ­£ç¡®æ³¨å†Œ
python -m lm_eval --tasks list | grep single_turn_scenarios

# æµ‹è¯•åŸºç¡€åŠŸèƒ½
python -m lm_eval --model dummy --tasks single_turn_scenarios_function_generation --limit 1 --predict_only

# æ£€æŸ¥APIå¯†é’¥è®¾ç½®
echo $ANTHROPIC_API_KEY
echo $OPENAI_API_KEY

# éªŒè¯ç¯å¢ƒé…ç½®
python -c "import lm_eval; print('lm-evalå¯¼å…¥æˆåŠŸ')"
python -c "import evaluation_engine; print('evaluation engineå¯¼å…¥æˆåŠŸ')"
```

### è°ƒè¯•æ¨¡å¼
```bash
# å¯ç”¨Pythonè°ƒè¯•æ¨¡å¼
python -m pdb -m lm_eval --model claude-local --tasks single_turn_scenarios_function_generation --limit 1

# è¯¦ç»†é”™è¯¯è¿½è¸ª
python -m lm_eval --model claude-local --tasks single_turn_scenarios_function_generation --limit 1 --verbosity DEBUG 2>&1 | tee debug.log
```

## ğŸ“‹ å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹

### æ ‡å‡†è¯„ä¼°æµç¨‹
```bash
# 1. è®¾ç½®ç¯å¢ƒ
source venv/bin/activate
export ANTHROPIC_API_KEY="your_key_here"

# 2. è¿è¡ŒåŸºç¡€æµ‹è¯•
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_function_generation --limit 1 --predict_only

# 3. è¿è¡Œå®Œæ•´è¯„ä¼°
python -m lm_eval --model claude-local --model_args model=claude-3-haiku-20240307 \
  --tasks single_turn_scenarios_function_generation,single_turn_scenarios_code_completion \
  --limit 5 --output_path results/my_evaluation.json --log_samples

# 4. æŸ¥çœ‹ç»“æœ
cat results/my_evaluation_*.json | jq '.results'

# 5. è¿è¡Œåˆ†æå·¥å…·
python demo_analysis_tools.py

# 6. ç”ŸæˆæŠ¥å‘Š
python evaluation_engine/tests/analysis_tools/test_analysis_tools.py
```

### æ‰¹é‡æ¨¡å‹æ¯”è¾ƒ
```bash
# æ¯”è¾ƒä¸åŒæ¨¡å‹æ€§èƒ½
models=("claude-3-haiku-20240307" "claude-3-5-sonnet-20241022")
task="single_turn_scenarios_function_generation"

for model in "${models[@]}"; do
    echo "è¯„ä¼°æ¨¡å‹: $model"
    python -m lm_eval --model claude-local --model_args model=$model \
      --tasks $task --limit 3 \
      --output_path results/comparison_${model//[-.]/_}.json
done

echo "æ‰€æœ‰æ¨¡å‹è¯„ä¼°å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ results/ ç›®å½•"
```

## ğŸ“ è·å–å¸®åŠ©

### æ–‡æ¡£èµ„æº
- `evaluation_engine/tests/README.md` - æµ‹è¯•å¥—ä»¶è¯¦ç»†è¯´æ˜
- `evaluation_engine/tests/analysis_tools/USAGE.md` - åˆ†æå·¥å…·ä½¿ç”¨æŒ‡å—
- `evaluation_engine/tests/specialized/USAGE.md` - ä¸“é¡¹åŠŸèƒ½è¯´æ˜
- `README.md` - é¡¹ç›®æ€»ä½“è¯´æ˜

### å‘½ä»¤è¡Œå¸®åŠ©
```bash
# æŸ¥çœ‹lm-evalå¸®åŠ©
python -m lm_eval --help

# æŸ¥çœ‹å¯ç”¨ä»»åŠ¡
python -m lm_eval --tasks list

# æŸ¥çœ‹å¯ç”¨æ¨¡å‹
python -m lm_eval --model list
```

## ğŸŒ API è°ƒç”¨æ–¹å¼

### å¯åŠ¨APIæœåŠ¡å™¨
```bash
# æ–¹å¼ä¸€ï¼šç›´æ¥å¯åŠ¨
python start_api_server.py

# æ–¹å¼äºŒï¼šä½¿ç”¨é«˜çº§é…ç½®å¯åŠ¨
python evaluation_engine/docs/advanced_config_examples.py
```

### APIè®¤è¯å’ŒåŸºç¡€è°ƒç”¨
```bash
# è·å–è®¿é—®ä»¤ç‰Œ
curl -X POST "http://localhost:8000/auth/login" \
  -H "Content-Type: application/json" \
  -d '{"username": "admin", "password": "admin123"}'

# è®¾ç½®ä»¤ç‰Œ
export ACCESS_TOKEN="your_token_here"

# åˆ›å»ºè¯„ä¼°ä»»åŠ¡
curl -X POST "http://localhost:8000/evaluations" \
  -H "Authorization: Bearer $ACCESS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "claude-3-haiku",
    "task_ids": ["single_turn_scenarios_function_generation"],
    "configuration": {"temperature": 0.7, "max_tokens": 1024}
  }'

# æŸ¥çœ‹è¯„ä¼°çŠ¶æ€
curl -X GET "http://localhost:8000/evaluations/eval_id" \
  -H "Authorization: Bearer $ACCESS_TOKEN"
```

### WebSocketå®æ—¶ç›‘æ§
```javascript
const ws = new WebSocket('ws://localhost:8000/ws?token=' + ACCESS_TOKEN);
ws.onmessage = function(event) {
    const data = JSON.parse(event.data);
    console.log('Progress:', data.data.progress);
};
```

### APIä»»åŠ¡é…ç½®
```bash
# åˆ—å‡ºæ‰€æœ‰å¯ç”¨ä»»åŠ¡
curl -X GET "http://localhost:8000/tasks" \
  -H "Authorization: Bearer $ACCESS_TOKEN" \
  -G -d "category=single_turn" -d "limit=20"

# è·å–ä»»åŠ¡è¯¦æƒ…
curl -X GET "http://localhost:8000/tasks/single_turn_scenarios_function_generation" \
  -H "Authorization: Bearer $ACCESS_TOKEN"

# åˆ›å»ºè‡ªå®šä¹‰ä»»åŠ¡
curl -X POST "http://localhost:8000/tasks/custom" \
  -H "Authorization: Bearer $ACCESS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "task_id": "custom_python_debugging",
    "name": "Python Debugging Task",
    "category": "single_turn",
    "difficulty": "advanced",
    "configuration": {
      "generation_config": {
        "temperature": 0.3,
        "max_tokens": 1024
      },
      "evaluation_config": {
        "metrics": ["fix_accuracy", "code_quality"],
        "evaluation_criteria": {
          "fix_accuracy": {"weight": 0.6, "threshold": 0.8},
          "code_quality": {"weight": 0.4, "threshold": 0.7}
        }
      }
    }
  }'

# éªŒè¯ä»»åŠ¡é…ç½®
curl -X POST "http://localhost:8000/tasks/custom_python_debugging/validate" \
  -H "Authorization: Bearer $ACCESS_TOKEN"

# æµ‹è¯•ä»»åŠ¡
curl -X POST "http://localhost:8000/tasks/custom_python_debugging/test" \
  -H "Authorization: Bearer $ACCESS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "sample_input": {"code": "def divide(a, b): return a / b"},
    "model_id": "claude-3-haiku"
  }'
```

## âš™ï¸ é«˜çº§é…ç½®ç¤ºä¾‹

### è¿è¡Œé«˜çº§é…ç½®ç¤ºä¾‹
```bash
# è¿è¡Œå®Œæ•´çš„é«˜çº§é…ç½®ç¤ºä¾‹
python evaluation_engine/docs/advanced_config_examples.py

# è¿è¡Œå®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹
python evaluation_engine/docs/complete_workflow_example.py
```

### æ¨¡å‹é…ç½®ç®¡ç†
```python
from evaluation_engine.core.advanced_model_config import ModelConfiguration

# åˆ›å»ºé«˜çº§æ¨¡å‹é…ç½®
config = ModelConfiguration(
    model_id="claude-3-haiku",
    temperature=0.7,
    max_tokens=2048,
    rate_limit_config=RateLimitConfig(
        requests_per_minute=60,
        tokens_per_minute=100000
    ),
    task_optimizations={
        TaskType.CODE_COMPLETION: {
            "temperature": 0.2,
            "max_tokens": 512
        }
    }
)
```

### A/Bæµ‹è¯•é…ç½®
```python
# åˆ›å»ºA/Bæµ‹è¯•
test_config = ab_test_manager.create_ab_test(
    test_id="temperature_test",
    variants={"low_temp": config_a, "high_temp": config_b},
    traffic_split={"low_temp": 0.5, "high_temp": 0.5}
)
```

### æ‰¹é‡è¯„ä¼°å’Œæ¯”è¾ƒ
```bash
# è¿è¡Œæ‰¹é‡æ¨¡å‹æ¯”è¾ƒ
python -c "
import asyncio
from evaluation_engine.docs.advanced_config_examples import AdvancedConfigurationExamples
examples = AdvancedConfigurationExamples()
asyncio.run(examples.run_batch_evaluation_example())
"
```

## ğŸ“Š å®Œæ•´æ‰§è¡Œæµç¨‹

### ç«¯åˆ°ç«¯è¯„ä¼°æµç¨‹
```bash
# 1. ç¯å¢ƒè®¾ç½®
source venv/bin/activate
export ANTHROPIC_API_KEY="your_key"

# 2. è¿è¡Œå®Œæ•´å·¥ä½œæµç¨‹
python evaluation_engine/docs/complete_workflow_example.py

# 3. æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Š
ls -la reports/
cat reports/comprehensive_report_*.json | jq '.'
```

### è‡ªå®šä¹‰è¯„ä¼°æµç¨‹
```python
# åˆ›å»ºè‡ªå®šä¹‰è¯„ä¼°è®¡åˆ’
evaluation_plan = {
    "models": ["claude-3-haiku", "gpt-3.5-turbo"],
    "tasks": ["single_turn_scenarios_function_generation"],
    "configurations": [
        {"name": "conservative", "temperature": 0.3},
        {"name": "balanced", "temperature": 0.7}
    ]
}

# æ‰§è¡Œè¯„ä¼°
results = await run_comprehensive_evaluation(evaluation_plan)
```

## ğŸ“ˆ æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

### å¯ç”¨æ€§èƒ½ç›‘æ§
```python
from evaluation_engine.core.advanced_model_config import PerformanceMonitor

monitor = PerformanceMonitor()
monitor.auto_scaling_enabled = True
monitor.start_monitoring()

# è®°å½•æ€§èƒ½æ•°æ®
monitor.record_performance("claude-3-haiku", 3.5, True, 0.05, 0.85)

# è·å–æ‰©å±•å»ºè®®
recommendations = monitor.get_scaling_recommendations("claude-3-haiku")
```

### é…ç½®æ–‡ä»¶ç®¡ç†
```yaml
# model_configs.yaml
models:
  claude-3-haiku:
    temperature: 0.7
    max_tokens: 2048
    rate_limits:
      requests_per_minute: 60
    task_optimizations:
      code_completion:
        temperature: 0.2
```

---

**æ³¨æ„**: æœ¬èœå•ä¸­çš„æ‰€æœ‰å‘½ä»¤éƒ½ç»è¿‡å®é™…æµ‹è¯•éªŒè¯ï¼Œç¡®ä¿å¯ä»¥æ­£å¸¸è¿è¡Œå¹¶äº§ç”Ÿæœ‰æ•ˆçš„åˆ†ææŠ¥å‘Šã€‚APIè°ƒç”¨å’Œé«˜çº§é…ç½®åŠŸèƒ½æä¾›äº†æ›´å¼ºå¤§çš„è‡ªåŠ¨åŒ–å’Œå®šåˆ¶åŒ–èƒ½åŠ›ã€‚å»ºè®®ä»åŸºç¡€åŠŸèƒ½å¼€å§‹ï¼Œé€æ­¥æ¢ç´¢é«˜çº§åŠŸèƒ½ã€‚